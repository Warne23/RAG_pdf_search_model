{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7690832,"sourceType":"datasetVersion","datasetId":4486604}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q pypdf","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:02:10.754051Z","iopub.execute_input":"2024-02-24T22:02:10.754331Z","iopub.status.idle":"2024-02-24T22:02:25.296603Z","shell.execute_reply.started":"2024-02-24T22:02:10.754305Z","shell.execute_reply":"2024-02-24T22:02:25.295552Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install langchain\n!pip install -q transformers\n%pip install llama-index-llms-llama-cpp\n!pip -q install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:02:25.298854Z","iopub.execute_input":"2024-02-24T22:02:25.299230Z","iopub.status.idle":"2024-02-24T22:04:35.620549Z","shell.execute_reply.started":"2024-02-24T22:02:25.299192Z","shell.execute_reply":"2024-02-24T22:04:35.619588Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.1.9-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.21 (from langchain)\n  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\nCollecting langchain-core<0.2,>=0.1.26 (from langchain)\n  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\nCollecting langsmith<0.2.0,>=0.1.0 (from langchain)\n  Downloading langsmith-0.1.7-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.24.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (4.2.0)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.26->langchain)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m777.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nDownloading langchain-0.1.9-py3-none-any.whl (816 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.7-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.1.9 langchain-community-0.0.24 langchain-core-0.1.26 langsmith-0.1.7 orjson-3.9.15 packaging-23.2\nCollecting llama-index-llms-llama-cpp\n  Downloading llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl.metadata (695 bytes)\nCollecting llama-cpp-python<0.3.0,>=0.2.32 (from llama-index-llms-llama-cpp)\n  Downloading llama_cpp_python-0.2.50.tar.gz (36.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-llms-llama-cpp)\n  Downloading llama_index_core-0.10.12-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (4.9.0)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (1.24.4)\nCollecting diskcache>=5.6.1 (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (3.1.2)\nRequirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.1)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.9.1)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.3)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.14)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.12.2)\nCollecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\nCollecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl.metadata (762 bytes)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.5.8)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.2.1)\nCollecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.1.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (9.5.0)\nRequirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.2.3)\nCollecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.66.1)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.9.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.0.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.14.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (2.1.3)\nRequirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.5.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.11.17)\nCollecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.14.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.12.25)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.20.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.0)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.14.6)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.16.0)\nDownloading llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl (5.1 kB)\nDownloading llama_index_core-0.10.12-py3-none-any.whl (15.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading openai-1.12.0-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.50-cp310-cp310-manylinux_2_31_x86_64.whl size=2623430 sha256=5c16594e42511ae85974792b89517a6c5b05359955eb015982615b454fdef219\n  Stored in directory: /root/.cache/pip/wheels/aa/86/b5/60afef0265d0fd0a5a193909db85382833ed61cd2ecf3ce138\nSuccessfully built llama-cpp-python\nInstalling collected packages: dirtyjson, nltk, httpcore, diskcache, tiktoken, llama-cpp-python, httpx, openai, llamaindex-py-client, llama-index-core, llama-index-llms-llama-cpp\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dirtyjson-1.0.8 diskcache-5.6.3 httpcore-1.0.4 httpx-0.27.0 llama-cpp-python-0.2.50 llama-index-core-0.10.12 llama-index-llms-llama-cpp-0.1.3 llamaindex-py-client-0.1.13 nltk-3.8.1 openai-1.12.0 tiktoken-0.6.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install llama-index-embeddings-langchain\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:04:35.622101Z","iopub.execute_input":"2024-02-24T22:04:35.622475Z","iopub.status.idle":"2024-02-24T22:04:49.089326Z","shell.execute_reply.started":"2024-02-24T22:04:35.622437Z","shell.execute_reply":"2024-02-24T22:04:49.088253Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting llama-index-embeddings-langchain\n  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl.metadata (663 bytes)\nRequirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-langchain) (0.10.12)\nRequirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.1)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.3)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.12.2)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\nRequirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.1.13)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.5.8)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.2.1)\nRequirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.8.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.24.4)\nRequirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.12.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.1.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (9.5.0)\nRequirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.2.3)\nRequirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.66.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.9.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.0.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.14.1)\nRequirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.5.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.11.17)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.4)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.12.25)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.20.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.0)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.14.6)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\nDownloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\nInstalling collected packages: llama-index-embeddings-langchain\nSuccessfully installed llama-index-embeddings-langchain-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install  llama-cpp-python --no-cache-dir","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:04:49.091650Z","iopub.execute_input":"2024-02-24T22:04:49.091952Z","iopub.status.idle":"2024-02-24T22:05:01.879149Z","shell.execute_reply.started":"2024-02-24T22:04:49.091924Z","shell.execute_reply":"2024-02-24T22:05:01.878180Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.2.50)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.9.0)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.24.4)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q llama-index\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:05:01.880589Z","iopub.execute_input":"2024-02-24T22:05:01.880920Z","iopub.status.idle":"2024-02-24T22:05:49.297784Z","shell.execute_reply.started":"2024-02-24T22:05:01.880890Z","shell.execute_reply":"2024-02-24T22:05:49.296548Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import logging\nimport sys\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:05:49.299300Z","iopub.execute_input":"2024-02-24T22:05:49.299610Z","iopub.status.idle":"2024-02-24T22:05:53.232540Z","shell.execute_reply.started":"2024-02-24T22:05:49.299582Z","shell.execute_reply":"2024-02-24T22:05:53.231603Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"NumExpr defaulting to 4 threads.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reading Documents","metadata":{}},{"cell_type":"code","source":"documents = SimpleDirectoryReader(\"/kaggle/input/dataset1\").load_data()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:05:53.233817Z","iopub.execute_input":"2024-02-24T22:05:53.234549Z","iopub.status.idle":"2024-02-24T22:06:03.841441Z","shell.execute_reply.started":"2024-02-24T22:05:53.234507Z","shell.execute_reply":"2024-02-24T22:06:03.840614Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Building RAG Model","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom llama_index.llms.llama_cpp import LlamaCPP\n# from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\nllm = LlamaCPP(\n    # You can pass in the URL to a GGML model to download it automatically\n    model_url='https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf',\n    # optionally, you can set the path to a pre-downloaded model instead of model_url\n    model_path=None,\n    temperature=0.1,\n    max_new_tokens=256,\n    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n    context_window=3900,\n    # kwargs to pass to __call__()\n    generate_kwargs={},\n    # kwargs to pass to __init__()\n    # set to at least 1 to use GPU\n    model_kwargs={\"n_gpu_layers\": -1},\n    # transform inputs into Llama2 format\n#     messages_to_prompt=messages_to_prompt,\n#     completion_to_prompt=completion_to_prompt,\n    verbose=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:06:03.842559Z","iopub.execute_input":"2024-02-24T22:06:03.842879Z","iopub.status.idle":"2024-02-24T22:06:35.911418Z","shell.execute_reply.started":"2024-02-24T22:06:03.842842Z","shell.execute_reply":"2024-02-24T22:06:35.910500Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading url https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf to path /tmp/llama_index/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf\ntotal size (MB): 4368.44\n","output_type":"stream"},{"name":"stderr","text":"4167it [00:24, 166.69it/s]                          \nllama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /tmp/llama_index/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\nllama_model_loader: - kv   2:                       llama.context_length u32              = 32768\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   4:                          llama.block_count u32              = 32\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\nllama_model_loader: - kv  11:                          general.file_type u32              = 15\nllama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  19:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q4_K:  193 tensors\nllama_model_loader: - type q6_K:   33 tensors\nllm_load_vocab: special tokens definition check successful ( 259/32000 ).\nllm_load_print_meta: format           = GGUF V2\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = SPM\nllm_load_print_meta: n_vocab          = 32000\nllm_load_print_meta: n_merges         = 0\nllm_load_print_meta: n_ctx_train      = 32768\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 8\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 4\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: n_ff             = 14336\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 10000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_yarn_orig_ctx  = 32768\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: model type       = 7B\nllm_load_print_meta: model ftype      = Q4_K - Medium\nllm_load_print_meta: model params     = 7.24 B\nllm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \nllm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\nllm_load_print_meta: BOS token        = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\nllm_load_print_meta: UNK token        = 0 '<unk>'\nllm_load_print_meta: LF token         = 13 '<0x0A>'\nllm_load_tensors: ggml ctx size =    0.11 MiB\nllm_load_tensors:        CPU buffer size =  4165.37 MiB\n.................................................................................................\nllama_new_context_with_model: n_ctx      = 3900\nllama_new_context_with_model: freq_base  = 10000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =   487.50 MiB\nllama_new_context_with_model: KV self size  =  487.50 MiB, K (f16):  243.75 MiB, V (f16):  243.75 MiB\nllama_new_context_with_model:        CPU input buffer size   =    16.65 MiB\nllama_new_context_with_model:        CPU compute buffer size =   275.75 MiB\nllama_new_context_with_model: graph splits (measure): 1\nAVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \nModel metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom llama_index.embeddings.langchain import LangchainEmbedding\n\nembed_model = LangchainEmbedding(\n  HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:06:35.912869Z","iopub.execute_input":"2024-02-24T22:06:35.913489Z","iopub.status.idle":"2024-02-24T22:06:50.479260Z","shell.execute_reply.started":"2024-02-24T22:06:35.913452Z","shell.execute_reply":"2024-02-24T22:06:50.478383Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Load pretrained SentenceTransformer: thenlper/gte-large\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8abdaac70b9045a09dd7f708b7f14e40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/67.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb08992d0844972b410c0cf50fc79eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec0eacbc2aca4282962b76d4e3fcc1d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552c5a778d104b80aa3ff00d1f35cca6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"857fda8c690b4768b688e081a2bdc1da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8afca2f38248abb3603b4fac489a9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff7643eba954a55a9203fa5905543df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd21061d0194185b685d96269db1c67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93bb4f708654cd9b05d02d2c181077d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d23d5e166cd44e8fa38246c076d88f39"}},"metadata":{}},{"name":"stdout","text":"Use pytorch device_name: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.core import ServiceContext\nservice_context = ServiceContext.from_defaults(\n#     chunk_size=256,\n    chunk_size=512,\n    llm=llm,\n    embed_model=embed_model\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:06:50.482660Z","iopub.execute_input":"2024-02-24T22:06:50.483204Z","iopub.status.idle":"2024-02-24T22:06:53.587206Z","shell.execute_reply.started":"2024-02-24T22:06:50.483176Z","shell.execute_reply":"2024-02-24T22:06:53.586378Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2809863808.py:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n  service_context = ServiceContext.from_defaults(\n","output_type":"stream"}]},{"cell_type":"code","source":"index = VectorStoreIndex.from_documents(documents, service_context=service_context)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:06:53.588249Z","iopub.execute_input":"2024-02-24T22:06:53.588506Z","iopub.status.idle":"2024-02-24T22:07:08.116944Z","shell.execute_reply.started":"2024-02-24T22:06:53.588483Z","shell.execute_reply":"2024-02-24T22:07:08.116110Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"query_engine = index.as_query_engine()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:07:08.118099Z","iopub.execute_input":"2024-02-24T22:07:08.118399Z","iopub.status.idle":"2024-02-24T22:07:08.189089Z","shell.execute_reply.started":"2024-02-24T22:07:08.118372Z","shell.execute_reply":"2024-02-24T22:07:08.188114Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"response = query_engine.query(\"what is an enzyme?\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:07:08.190436Z","iopub.execute_input":"2024-02-24T22:07:08.190799Z","iopub.status.idle":"2024-02-24T22:12:49.512855Z","shell.execute_reply.started":"2024-02-24T22:07:08.190765Z","shell.execute_reply":"2024-02-24T22:12:49.511967Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"\nllama_print_timings:        load time =  111706.46 ms\nllama_print_timings:      sample time =     122.20 ms /   220 runs   (    0.56 ms per token,  1800.37 tokens per second)\nllama_print_timings: prompt eval time =  268082.68 ms /  1194 tokens (  224.52 ms per token,     4.45 tokens per second)\nllama_print_timings:        eval time =   71868.88 ms /   219 runs   (  328.17 ms per token,     3.05 tokens per second)\nllama_print_timings:       total time =  341214.03 ms /  1413 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:12:49.514028Z","iopub.execute_input":"2024-02-24T22:12:49.514304Z","iopub.status.idle":"2024-02-24T22:12:49.519040Z","shell.execute_reply.started":"2024-02-24T22:12:49.514280Z","shell.execute_reply":"2024-02-24T22:12:49.518211Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nAn enzyme is a type of protein that acts as a biological catalyst to speed up chemical reactions in living organisms. Enzymes are prized by chemists for their regio- and stereoselectivity, but their use is often restricted to a narrow spectrum of substrates. Enzymes have the unusual ability to recognize an isolated chemical module and have so far been discovered empirically. Enzymes with the unusual ability to recognize an isolated chemi-cal module have so far been discovered empirically. The recent crystal structures of penicillin G acylase and of several lipases offer mechanistic insights into their mode of action. Both structures reveal shallow active sites, with variable regions of the substrate directed outwards into solvent. Enzymes involved in nutrient recruitment and chemical warfare may have evolved underselective pressure to tolerate diverse substrates. Consequently, proteins involved in these processes might be expected to provide a rich source of undiscovered catalysts for enzymatic biotransformation.\n","output_type":"stream"}]},{"cell_type":"code","source":"response = query_engine.query(\"how do you detect modular enzyme?\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:12:49.520268Z","iopub.execute_input":"2024-02-24T22:12:49.520989Z","iopub.status.idle":"2024-02-24T22:18:12.012453Z","shell.execute_reply.started":"2024-02-24T22:12:49.520957Z","shell.execute_reply":"2024-02-24T22:18:12.011510Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  111706.46 ms\nllama_print_timings:      sample time =      95.34 ms /   168 runs   (    0.57 ms per token,  1762.19 tokens per second)\nllama_print_timings: prompt eval time =  266951.26 ms /  1183 tokens (  225.66 ms per token,     4.43 tokens per second)\nllama_print_timings:        eval time =   54488.03 ms /   167 runs   (  326.28 ms per token,     3.06 tokens per second)\nllama_print_timings:       total time =  322411.77 ms /  1350 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:18:12.013711Z","iopub.execute_input":"2024-02-24T22:18:12.014002Z","iopub.status.idle":"2024-02-24T22:18:12.018910Z","shell.execute_reply.started":"2024-02-24T22:18:12.013977Z","shell.execute_reply":"2024-02-24T22:18:12.018005Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nTo detect a modular enzyme, it must have a modular architecture, which typically implies the existence of multiple domains (or subunits, in the case of an oligomeric enzyme). Formally, domains are defined as stable globular fragments of proteins that may refold autonomously and carry out specific functions. They are identified typically by computer algorithms that search for segments (of about 50–500 residues) with sequence similarity within a group of larger, functionally distinct polypeptides. Experimental evidence for modularity requires satisfaction of two criteria: distinct properties must be able to be assigned to each domain, identified by means of either proteolysis or protein engineering; and it should be possible to recombine these domains to generate functional chimaeras.\n","output_type":"stream"}]},{"cell_type":"code","source":"response = query_engine.query(\"what are some of Yugdeep's projects?\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:18:12.020389Z","iopub.execute_input":"2024-02-24T22:18:12.020726Z","iopub.status.idle":"2024-02-24T22:23:36.716440Z","shell.execute_reply.started":"2024-02-24T22:18:12.020696Z","shell.execute_reply":"2024-02-24T22:23:36.715465Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  111706.46 ms\nllama_print_timings:      sample time =      59.95 ms /   110 runs   (    0.54 ms per token,  1834.92 tokens per second)\nllama_print_timings: prompt eval time =  287695.34 ms /  1273 tokens (  226.00 ms per token,     4.42 tokens per second)\nllama_print_timings:        eval time =   36291.49 ms /   109 runs   (  332.95 ms per token,     3.00 tokens per second)\nllama_print_timings:       total time =  324617.15 ms /  1382 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:23:36.717809Z","iopub.execute_input":"2024-02-24T22:23:36.718439Z","iopub.status.idle":"2024-02-24T22:23:36.723783Z","shell.execute_reply.started":"2024-02-24T22:23:36.718404Z","shell.execute_reply":"2024-02-24T22:23:36.722871Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\n- Data Science Intern – Mowito Inc. (May’23 - July’23)\n- Research Intern - IIM Ahmedabad (May’22 - July’22)\n- Hate Tweet Classification (Dec’22)\n- Employee Attrition Rate Prediction (Aug’22)\n- Marketing and Industrial Relations Executive (July’21 - July’22)\n- Operations Head (July’22 - July’23)\n","output_type":"stream"}]},{"cell_type":"code","source":"response=query_engine.query('Who is president of USA?')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:23:36.724987Z","iopub.execute_input":"2024-02-24T22:23:36.725300Z","iopub.status.idle":"2024-02-24T22:26:58.284746Z","shell.execute_reply.started":"2024-02-24T22:23:36.725270Z","shell.execute_reply":"2024-02-24T22:26:58.283843Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  111706.46 ms\nllama_print_timings:      sample time =       8.59 ms /    15 runs   (    0.57 ms per token,  1745.81 tokens per second)\nllama_print_timings: prompt eval time =  196973.70 ms /   880 tokens (  223.83 ms per token,     4.47 tokens per second)\nllama_print_timings:        eval time =    4428.42 ms /    14 runs   (  316.32 ms per token,     3.16 tokens per second)\nllama_print_timings:       total time =  201488.05 ms /   894 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:26:58.286122Z","iopub.execute_input":"2024-02-24T22:26:58.286494Z","iopub.status.idle":"2024-02-24T22:26:58.291455Z","shell.execute_reply.started":"2024-02-24T22:26:58.286449Z","shell.execute_reply":"2024-02-24T22:26:58.290629Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":" The context information does not provide any information about the president of USA.\n","output_type":"stream"}]},{"cell_type":"code","source":"response=query_engine.query('who is the prime minister of India. If you dont know say Yugdeep.')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:26:58.292616Z","iopub.execute_input":"2024-02-24T22:26:58.292918Z","iopub.status.idle":"2024-02-24T22:30:53.856113Z","shell.execute_reply.started":"2024-02-24T22:26:58.292894Z","shell.execute_reply":"2024-02-24T22:30:53.855161Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  111706.46 ms\nllama_print_timings:      sample time =       2.14 ms /     4 runs   (    0.53 ms per token,  1872.66 tokens per second)\nllama_print_timings: prompt eval time =  234463.31 ms /  1034 tokens (  226.75 ms per token,     4.41 tokens per second)\nllama_print_timings:        eval time =     950.74 ms /     3 runs   (  316.91 ms per token,     3.16 tokens per second)\nllama_print_timings:       total time =  235446.39 ms /  1037 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:30:53.857338Z","iopub.execute_input":"2024-02-24T22:30:53.857667Z","iopub.status.idle":"2024-02-24T22:30:53.862546Z","shell.execute_reply.started":"2024-02-24T22:30:53.857640Z","shell.execute_reply":"2024-02-24T22:30:53.861636Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":" Yugdeep\n","output_type":"stream"}]},{"cell_type":"code","source":"response=query_engine.query('How to run a Virtual Server on AWS')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:30:53.863918Z","iopub.execute_input":"2024-02-24T22:30:53.864620Z","iopub.status.idle":"2024-02-24T22:34:55.496455Z","shell.execute_reply.started":"2024-02-24T22:30:53.864586Z","shell.execute_reply":"2024-02-24T22:34:55.495575Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  111706.46 ms\nllama_print_timings:      sample time =     111.28 ms /   194 runs   (    0.57 ms per token,  1743.37 tokens per second)\nllama_print_timings: prompt eval time =  178103.14 ms /   798 tokens (  223.19 ms per token,     4.48 tokens per second)\nllama_print_timings:        eval time =   62043.16 ms /   193 runs   (  321.47 ms per token,     3.11 tokens per second)\nllama_print_timings:       total time =  241562.30 ms /   991 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T22:34:55.497721Z","iopub.execute_input":"2024-02-24T22:34:55.498008Z","iopub.status.idle":"2024-02-24T22:34:55.502462Z","shell.execute_reply.started":"2024-02-24T22:34:55.497983Z","shell.execute_reply":"2024-02-24T22:34:55.501639Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\nTo run a Virtual Server on AWS, follow these steps:\n\n1. Sign in to the AWS Management Console and navigate to the EC2 dashboard.\n2. Click on the \"Launch Instance\" button.\n3. Select an Amazon Machine Image (AMI) that you want to use as the base for your virtual server.\n4. Choose an instance type that meets your needs.\n5. Configure any additional settings, such as network interfaces, storage, and security groups.\n6. Review and launch your instance.\n7. Connect to your instance using SSH or another method, such as RDP if you are using a Windows instance.\n8. Once connected, you can use standard Linux commands to install software and perform other tasks on your virtual server.\n9. To terminate your instance, navigate to the EC2 dashboard, select your instance, and click on the \"Terminate\" button.\n","output_type":"stream"}]}]}